# -*- coding: utf-8 -*-
"""npy_segmentation_approach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tXrQfcCWuexau_iKBiqHabmqQQjX2uO7
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from tensorflow import keras
# import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Reshape
from keras.layers import Conv1D, MaxPooling1D, BatchNormalization
import os
import random
import time

import pandas as pd
import numpy as np
import os

dataset_dir  = '/content/drive/MyDrive/BCI/npy_dataset'

eeg_data = []
labels = []
for file in os.listdir(dataset_dir):
    if file.endswith(".npy"):
        data = np.load(os.path.join(dataset_dir,file), allow_pickle=True)
        eeg_data.append(data)
        labels.append(file.split("-")[0])

print(len(eeg_data))
print(len(labels))

print(labels[5])

from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils
encoder = LabelEncoder()
encoder.fit(labels)
y = encoder.transform(labels)
original_labels = encoder.inverse_transform(y)
#labels2 = encoder.inverse_transform(original_labels)
y = encoder.transform(labels)
Y = np_utils.to_categorical(y, 6)
original_labels, y, Y

print(Y[5])

from sklearn.preprocessing import StandardScaler

# Initialize a StandardScaler object
scaler = StandardScaler()

for i in range(len(eeg_data)):
    scaler = StandardScaler()
    scaler.fit(eeg_data[i])
    eeg_data[i] = scaler.transform(eeg_data[i])

print(eeg_data)

print(eeg_data[0].shape)

from sklearn.model_selection import train_test_split
import numpy

data = numpy.array(eeg_data)  #convert array to numpy type array

X_train, X_test, y_train, y_test  = train_test_split(data,Y,test_size=0.2
                                                    # ,random_state=42
                                                     ,stratify=Y
                                                     ,shuffle=True
                                                     )

print(len(X_train))
print(len(X_test))

print(len(y_train))
print(len(y_test))

train_X = numpy.array(X_train)
test_X = numpy.array(X_test)

train_y = np.array(y_train)
test_y = np.array(y_test)

train_X

print(train_X.shape)

print(test_y)

# model = Sequential()

# model.add(Conv1D(64, (3), input_shape=train_X.shape[1:]))
# model.add(Activation('relu'))

# model.add(Conv1D(64, (2)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(2)))

# model.add(Conv1D(64, (2)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(2)))

# model.add(Flatten())

# model.add(Dense(512))

# model.add(Dense(6))
# model.add(Activation('softmax'))

# model.compile(loss='categorical_crossentropy',
#               optimizer='adam',
#               metrics=['accuracy'])


# model.add(Conv1D(64, (8), input_shape=train_X.shape[1:]))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (6)))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (6)))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (4)))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (4)))
# model.add(Activation('relu'))

# model.add(Conv1D(64, (4)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(4)))

# model.add(Conv1D(64, (2)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(4)))

# model.add(Flatten())

# # model.add(Dense(512))
# # model.add(Dense(256))
# # model.add(Dense(128))
# # model.add(Dense(64))
# # model.add(Dense(32))
# # model.add(Dense(16))

# model.add(Dense(6))
# model.add(Activation('softmax'))

# model.compile(loss='categorical_crossentropy',
#               optimizer='adam',
#               metrics=['accuracy'])

# model.add(Conv1D(512, (3), input_shape=train_X.shape[1:]))
# model.add(Activation('relu'))

# model.add(Conv1D(256, (2)))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (2)))
# model.add(Activation('relu'))

# model.add(Conv1D(128, (2)))
# model.add(Activation('relu'))

# model.add(Conv1D(64, (2)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(2)))

# model.add(Conv1D(64, (2)))
# model.add(Activation('relu'))
# model.add(MaxPooling1D(pool_size=(2)))

# model.add(Flatten())

# model.add(Dense(512))
# model.add(Dense(256))
# model.add(Dense(128))

# model.add(Dense(6))
# model.add(Activation('softmax'))

# model.compile(loss='categorical_crossentropy',
#               optimizer='adam',
#               metrics=['accuracy'])

model = Sequential()
model.add(Conv1D(64, (8), input_shape=train_X.shape[]))
model.add(Activation('relu'))

model.add(Conv1D(128, (4)))
model.add(Activation('relu'))

model.add(Conv1D(128, (4)))
model.add(Activation('relu'))

model.add(Conv1D(64, (4)))
model.add(Activation('relu'))
model.add(MaxPooling1D(pool_size=(4)))

model.add(Conv1D(64, (4)))
model.add(Activation('relu'))
model.add(MaxPooling1D(pool_size=(4)))

model.add(Flatten())

model.add(Dense(6))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='nadam',
              metrics=['accuracy'])

model.fit(train_X, train_y, epochs=100, batch_size=5)

score = model.evaluate(test_X, test_y, batch_size=5)
print(score)

#Predict
from sklearn.metrics import confusion_matrix

y_prediction = model.predict(test_X)
y_prediction = np.argmax (y_prediction, axis = 1)
y_test=np.argmax(test_y, axis=1)

import itertools
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np

y_prediction = model.predict(test_X)
y_prediction = np.argmax (y_prediction, axis = 1)
y_test=np.argmax(test_y, axis=1)

# Number of classes
num_classes = len(np.unique(y_test))
labels=['backward','down','forward','left','right','up']

# Compute confusion matrix
confusion_mat = confusion_matrix(y_test, y_prediction)


# Normalize the confusion matrix
confusion_mat = confusion_mat.astype('float') / confusion_mat.sum(axis=1)[:, np.newaxis]

# Create the plot
plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.colorbar()
tick_marks = np.arange(num_classes)
plt.xticks(tick_marks, y)
plt.yticks(tick_marks, original_labels)

# Add values to the plot
thresh = confusion_mat.max() / 2.
for i, j in itertools.product(range(confusion_mat.shape[0]), range(confusion_mat.shape[1])):
    plt.text(j, i, format(confusion_mat[i, j], '.2f'),
             horizontalalignment="center",
             color="white" if confusion_mat[i, j] > thresh else "black")

# Add labels and adjust layout
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# from sklearn.metrics import classification_report
# y_true = [2, 0, 2, 2, 0, 1]
# y_pred = [0, 0, 2, 2, 0, 2]
# labels=['left','right','up','down','forward','backward']
# print(classification_report(y_test, y_prediction, target_names=original_labels))
# print(class_labels)

result = confusion_matrix(y_test, y_prediction , normalize='pred')
print(result)

class estimator:
  _estimator_type = ''
  classes_=[]
  def __init__(self, model, classes):
    self.model = model
    self._estimator_type = 'classifier'
    self.classes_ = classes
  def predict(self, X):
    y_prob= self.model.predict(X)
    y_pred = y_prob.argmax(axis=1)
    return y_pred

from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt

# y_true and y_pred are the true and predicted class labels, respectively
# classes is a list of class names
classes=['left','right','up','down','forward','backward']
classifier = estimator(model, classes)
plot_confusion_matrix(estimator=classifier, X=test_X, y_true=y_test)

import pickle
if score[1] >= 0.57:
  pickle.dump(model, open(str(score[1])+"-acc-cnn-model.sav", 'wb'))

print(model.summary())